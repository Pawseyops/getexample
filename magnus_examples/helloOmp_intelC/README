#!/bin/bash --login
# This is the README file is an executable script.
# To run type: ./README
#
# Example OBjECTIVE: to demostrate omp_hello.c example on Magnus
# on the Intel environment. omp_hello.c is an OpenMP code 
# and restricted to a single node.
# omp_hello.c is taken from 
# https://computing.llnl.gov/tutorials/openMP/exercise.html
# To run this code, we need to specify the number of tasks
# and the number of OpenMP threads.
# This information is located under hello_omp_intel.slurm
# You can edit the SLURM as: emacs hello_omp_intel.slurm &

# SLURM directives
# 
# Here we specify to SLURM we want 1 node (--nodes=1)
# To compile the code with Intel, we swap from Cray
# environment to Intel as shown below:
# module swap PrgEnv-cray PrgEnv-intel
# Then, we set the total number of threads to 24 as shown below:
# export OMP_NUM_THREADS=24
# To launch a job, we specify to aprun 1 OpenMP task (-n 1)
# with 24 threads (-d 24)
# Therefore, the aprun command looks like: 
# aprun -n 1 -d 24 ./$EXECUTABLE >> ${OUTPUT}

# To compile the omp_hello.c code with Intel
cc -O2 -openmp omp_hello.c -o hello_omp_intel

# To submit the job to Magnus
sbatch hello_omp_intel.slurm

echo "The sbatch command returns what jobid is for this job."
echo "To check the status of your job, use the slurm command:"
echo "squeue -u $USER"
echo "Your job is deleted from the scratch."
echo "It is now moved to your group."
echo "Your results are now located in ${MYGROUP}/hello_openmp_c_results/"
echo "To change to your jobID directory, type:"
echo "cd ${MYGROUP}/hello_openmp_c_results/jobID/"
echo "To view the results, use the cat command and type:"
echo "cat hello_omp_intel.log"
