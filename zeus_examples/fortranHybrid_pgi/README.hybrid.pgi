#!/bin/bash --login
# This is the README file is an executable script.
# To run type: ./README.hybrid.pgi
#
# Example OBjECTIVE: to demostrate hybrid_hello.f90 example
# on Zeus. 
# this code runs in the pgi module
# To run this code, we need to edit the partition, 
# load the necessary modules,
# specify the total number of MPI tasks and
# the number of OpenMP threads.
# This information is located under hello_hybrid_pgi.slurm
# You can edit the SLURM as: emacs hello_hybrid_pgi.slurm &

# SLURM directives
# 
# Here specify to SLURM that we want 2 nodes (--node=2)
# We the modify the partition to --partition==workq
# To compile with intel compiler, we need to unload 
# the gcc compiler as shown below:

# Then, we load the necessary modules before module listing.
# This script requires 2 nodes and runs 1 MPI process with
# 16 OpenMP threads on each intel compiled executable.
# Hence, we set the number of threads to 16 as shown below: 
# export OMP_NUM_THREADS=16
# The code is in PGI compiler suggesting that the job is OpenACC
# the resulting command looks like:
# ./$EXECUTABLE >> ${OUTPUT}
 
# To compile the hybrid_hello.f90 code with pgi compiler

mpif90 -mp -O2 hybrid_hello.f90 -o hello_hybrid_pgi

# hybrid_hello.f90 can be also compiled with:
# mpif90 -openmp hybrid_hello.f90 -o hello_hybrid_pgi

# This code also can be compiled with:
# mpif90 -openmp hybrid_hello.f90 -o hello_hybrid_pgi

# To submit the job to Zeus

sbatch hello_hybrid_pgi.slurm

echo "The sbatch command returns what jobid is for this job."
echo "To check the status of your job, use the slurm command:"
echo "squeue -u $USER"
echo "Your job is deleted from the scratch."
echo "It is now moved to your group."
echo "Your results are now located in ${MYGROUP}/hello_results_hybrid/"
echo "To change to your jobID directory, type:"
echo "cd ${MYGROUP}/hello_results_hybrid/jobID/"
echo "To view the results, use the cat command and type:"
echo "cat hello_hybrid_pgi.log"
