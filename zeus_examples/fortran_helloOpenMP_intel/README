#!/bin/bash --login
# This is the README file is an executable script.
# To run type: ./README
#
# Example OBjECTIVE: to demostrate omp_hello.f example
# on Zeus with Intel compiler. 
# omp_hello.c code is taken from
# https://computing.llnl.gov/tutorials/openMP/exercise.html
# cp the omp_hello.f source code
cp $GE_DIR/src/omp_hello.f .


# This code is an OpenMP example that runs one 16-thread
# OpenMP instance with one node.

# To run this code load the necessary modules.
# and specify the total number of OpenMP threads.
# This information is located under hello_omp_intel.slurm
# You can edit the SLURM as: emacs hello_omp_intel.slurm &

# SLURM directives
# 
# Here we specify to SLURM that we want 1 node (--nodes=1)
# Then, we modify the partition to --partition==workq
# To run this code correctly, we comment out: --export=NONE
# If this is not commented out, the code does not run.
# To compile the code with intel, we need to unload 
# the gcc module and load the intel module as shown below: 
module unload gcc
module load intel
# We also need to load the other necessary modules
# before module listing as shown:
module load mpt
# Then, we set the number of threads to 16 as shown below: 
# export OMP_NUM_THREADS=16
# Therefore, to run the code we simply type:
# omplace -nt $OMP_NUM_THREADS ./$EXECUTABLE >> ${OUTPUT}
# It is important to note that Intel compiler module is the default 
# for the omplace command above. If we use the omplace command above
# for a different module such as GNU, we need to add -tm open64 
# to the omplace invocation.
# An alternative way to run this job is to use the srun command as shown:
# srun -n 1 -c $OMP_NUM_THREADS ./$EXECUTABLE >> ${OUTPUT}
 
# To compile the omp_hello.f code with Intel
ifort -O2 -qopenmp omp_hello.f -o hello_omp_intel

# With intel compiler, -openmp does not compile the code.
# Therefore, we use -qopenmp as shown above.

# To submit the job to Zeus
sbatch hello_omp_intel.slurm
jobid=`squeue -u $USER | grep $USER | awk '{print $1}'`

echo "The sbatch command returns what the jobid is for this job."
echo "To check the status of your job, use the slurm command:"
echo "squeue -u $USER"
echo " "
echo "Your job will be run in $MYSCRATCH/run_fortran_helloOpenMP_intel/${jobid}."
echo " "
echo "Your results will be saved in ${MYGROUP}/fortran_helloOpenMP_intel_results_zeus/${jobid}"
echo "and the scratch directory will then be deleted."
echo " "
echo "To check the results change to your jobid directory, type:"
echo "cd ${MYGROUP}/fortran_helloOpenMP_intel_results_zeus/${jobid}"
echo " " 
echo "To view the results, use the cat command and type:"
echo "cat fortran_helloOpenMP_intel.log"
echo " "
echo " PAWSEY user shortcuts! " 
echo  '$MYSCRATCH' "is an environment variable it is set to $MYSCRATCH"
echo  '$MYGROUP' "is an environment variable it is set to $MYGROUP"
echo " example:  cd \$MYGROUP "
echo " "  
echo "more information about Zeus/Zython can be found at:"
echo " https://support.pawsey.org.au/documentation/pages/viewpage.action?pageId=2162999"
echo " "
echo "more information about SLURM and aprun can be found at:"
echo " https://support.pawsey.org.au/documentation/display/US/Scheduling+and+Running+Jobs"
echo " "
echo " "

