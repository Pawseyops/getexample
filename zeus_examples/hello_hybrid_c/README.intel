#!/bin/bash --login
# This is the README file is an executable script.
# To run type: ./README.intel
#
# Example OBjECTIVE: to demostrate hybrid_hello.c example
# on Zeus with Intel Compiler.
# To run this code, we need to edit the partition, 
# load the necessary modules,
# specify the total number of MPI tasks and
# the number of OpenMP threads.
# This information is located under hello_hybrid_intel.slurm
# You can edit the SLURM as: emacs hello_hybrid_intel.slurm &

# SLURM directives
# 
# Here specify to SLURM that we want 2 nodes (--node=2)
# We the modify the partition to --partition==workq
# To run this code correctly on Zeus, we need to remove --export=NONE
# If it is still included in the SLURM, the code does not compile.
# To compile with intel compiler, we need to unload 
# the gcc compiler as shown below:
# module unload gcc
# Then, we load the necessary modules before module listing.
# module load intel
# module load mpt
# This script requires 2 nodes and runs 1 MPI process with
# 16 OpenMP threads on each intel compiled executable.
# Hence, we set the number of threads to 16 as shown below: 
# export OMP_NUM_THREADS=16
# Therefore, the srun command looks like:
# srun --mpi=pmi2 -n 2 -N 2 ./$EXECUTABLE >> ${OUTPUT}
 
# To compile the hybrid_hello.c code with Intel compiler
mpicc -qopenmp hybrid_hello.c -o hello_hybrid_intel

# This code also can be compiled with:
# mpif90 -openmp hybrid_hello.c -o hello_hybrid_zeus

# To submit the job to Zeus
sbatch hello_hybrid_intel.slurm

echo "The sbatch command returns what jobid is for this job."
echo "To check the status of your job, use the slurm command:"
echo "squeue -u $USER"
echo "Your job is deleted from the scratch."
echo "It is now moved to your group."
echo "Your results are now located in ${MYGROUP}/hello_results_hybrid_c/"
echo "To change to your jobID directory, type:"
echo "cd ${MYGROUP}/hello_results_hybrid_c/jobID/"
echo "To view the results, use the cat command and type:"
echo "cat hello_hybrid_intel.log"
