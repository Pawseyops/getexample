#!/bin/bash
# This is the README file is an executable script.
# To run type: ./README
#
# Example OBjECTIVE: to demostrate hello_mpi.c example
# on Zeus. 
# To run this code, edit the partition and 
# load the necessary modules.
# This information is located under hello_gpu.slurm
# You can edit the SLURM as: emacs hello_gpu.slurm &

# SLURM directives
# 
# Here we specify to SLURM we want 1 node (--nodes=1)
# Change the partition to the GPU partition (--partition==workq)
# Add #SBATCH --gres=gpu:1
# Load the necessary modules before module listing.
# module load cuda

# To compile the hello_cuda.cu code

mpicc helloworld.mpi.c -o helloworld_mpi

# To submit the job to Magnus

sbatch helloworld_mpi.slurm

echo "The sbatch command returns what jobid is for this job."
echo "To check the status of your job, use the slurm command:"
echo "squeue -u $USER"
echo "Your job is deleted from the scratch."
echo "It is now moved to your group."
echo "Your results are now located in ${MYGROUP}/hello_gpu_results/"
echo "To change to your jobID directory, type:"
echo "cd ${MYGROUP}/helloworld_gpu_results/jobID/"
echo "To view the results, use the cat command and type:"
echo "cat helloworld.mpi.log"
